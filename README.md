<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

# Amazon Beauty Recommendation System (NumPy Implementation)

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![NumPy](https://img.shields.io/badge/Library-NumPy-green)
![Status](https://img.shields.io/badge/Status-Completed-brightgreen)

## ğŸ“‘ Má»¥c lá»¥c
- [1. Giá»›i thiá»‡u](#1-giá»›i-thiá»‡u)
- [2. Dataset](#2-dataset)
- [3. PhÆ°Æ¡ng phÃ¡p (Methodology)](#3-phÆ°Æ¡ng-phÃ¡p-methodology)
    - [Quy trÃ¬nh xá»­ lÃ½](#quy-trÃ¬nh-xá»­-lÃ½)
    - [Thuáº­t toÃ¡n & ToÃ¡n há»c](#thuáº­t-toÃ¡n--toÃ¡n-há»c)
    - [Ká»¹ thuáº­t NumPy](#ká»¹-thuáº­t-numpy-Ä‘Ã£-sá»­-dá»¥ng)
- [4. CÃ i Ä‘áº·t & Thiáº¿t láº­p](#4-cÃ i-Ä‘áº·t--thiáº¿t-láº­p)
- [5. HÆ°á»›ng dáº«n sá»­ dá»¥ng](#5-hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
- [6. Káº¿t quáº£ (Results)](#6-káº¿t-quáº£-results)
- [7. Cáº¥u trÃºc dá»± Ã¡n](#7-cáº¥u-trÃºc-dá»±-Ã¡n)
- [8. ThÃ¡ch thá»©c & Giáº£i phÃ¡p](#8-thÃ¡ch-thá»©c--giáº£i-phÃ¡p)
- [9. HÆ°á»›ng phÃ¡t triá»ƒn](#9-hÆ°á»›ng-phÃ¡t-triá»ƒn)
- [10. TÃ¡c giáº£](#10-tÃ¡c-giáº£)
- [11. Giáº¥y phÃ©p](#11-giáº¥y-phÃ©p)
---

## 1. Giá»›i thiá»‡u

Dá»± Ã¡n nÃ y táº­p trung xÃ¢y dá»±ng má»™t **Há»‡ thá»‘ng gá»£i Ã½ sáº£n pháº©m (Recommendation System)** cho ngÃ nh hÃ ng LÃ m Ä‘áº¹p (Beauty) trÃªn Amazon. Má»¥c tiÃªu chÃ­nh khÃ´ng chá»‰ lÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n, mÃ  lÃ  **á»©ng dá»¥ng sÃ¢u thÆ° viá»‡n NumPy** Ä‘á»ƒ cÃ i Ä‘áº·t cÃ¡c thuáº­t toÃ¡n Há»c mÃ¡y tá»« Ä‘áº§u (from scratch) mÃ  khÃ´ng phá»¥ thuá»™c vÃ o cÃ¡c thÆ° viá»‡n cao cáº¥p nhÆ° Scikit-learn hay TensorFlow.

Dá»± Ã¡n giáº£i quyáº¿t bÃ i toÃ¡n: *"Dá»±a trÃªn lá»‹ch sá»­ Ä‘Ã¡nh giÃ¡ cá»§a ngÆ°á»i dÃ¹ng, hÃ£y gá»£i Ã½ nhá»¯ng sáº£n pháº©m má»¹ pháº©m há» cÃ³ kháº£ nÄƒng thÃ­ch nháº¥t."*

---

## 2. Dataset

- **Nguá»“n dá»¯ liá»‡u:** Amazon - Ratings (Beauty Products).
- **Äáº·c Ä‘iá»ƒm:**
    - **User ID:** MÃ£ Ä‘á»‹nh danh ngÆ°á»i dÃ¹ng.
    - **Product ID:** MÃ£ Ä‘á»‹nh danh sáº£n pháº©m (ASIN).
    - **Rating:** Äiá»ƒm Ä‘Ã¡nh giÃ¡ (1-5 sao).
    - **Timestamp:** Thá»i gian Ä‘Ã¡nh giÃ¡.
- **Thá»‘ng kÃª sÆ¡ bá»™:**
    - Tá»•ng sá»‘ ratings: ~2,023,070.
    - Sá»‘ lÆ°á»£ng Users: ~1.2M.
    - Sá»‘ lÆ°á»£ng Products: ~249K.
    - **Äá»™ thÆ°a (Sparsity):** 99.99% (ÄÃ¢y lÃ  thÃ¡ch thá»©c lá»›n nháº¥t cá»§a bÃ i toÃ¡n).

---

## 3. PhÆ°Æ¡ng phÃ¡p (Methodology)

### Quy trÃ¬nh xá»­ lÃ½
1.  **Data Cleaning:** Loáº¡i bá» cÃ¡c rating khÃ´ng há»£p lá»‡, xá»­ lÃ½ trÃ¹ng láº·p.
2.  **Filtering (k-core):** Chá»‰ giá»¯ láº¡i cÃ¡c User vÃ  Product cÃ³ sá»‘ lÆ°á»£ng tÆ°Æ¡ng tÃ¡c Ä‘áº¡t ngÆ°á»¡ng nháº¥t Ä‘á»‹nh (vÃ­ dá»¥: >15 ratings) Ä‘á»ƒ giáº£m Ä‘á»™ thÆ°a vÃ  giáº£i quyáº¿t váº¥n Ä‘á» Cold-start.
3.  **Data Splitting:** Chia táº­p dá»¯ liá»‡u thÃ nh Train/Validation/Test theo tá»· lá»‡ (70/15/15).
4.  **Matrix Construction:** Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u log sang ma tráº­n thÆ°a (Sparse Matrix CSR) Ä‘á»ƒ tá»‘i Æ°u bá»™ nhá»›.

### Thuáº­t toÃ¡n & ToÃ¡n há»c
Dá»± Ã¡n cÃ i Ä‘áº·t 3 thuáº­t toÃ¡n chÃ­nh hoÃ n toÃ n báº±ng NumPy/SciPy:

#### a. User-Based Collaborative Filtering
Dá»± Ä‘oÃ¡n rating dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a cÃ¡c ngÆ°á»i dÃ¹ng.
- **CÃ´ng thá»©c Similarity (Cosine):**
  $$sim(u, v) = \frac{r_u \cdot r_v}{||r_u|| \cdot ||r_v||}$$
- **Dá»± Ä‘oÃ¡n:**
  $$\hat{r}_{ui} = \bar{r}_u + \frac{\sum_{v \in N_i(u)} sim(u, v) (r_{vi} - \bar{r}_v)}{\sum_{v \in N_i(u)} |sim(u, v)|}$$

#### b. Item-Based Collaborative Filtering
TÆ°Æ¡ng tá»± User-based nhÆ°ng tÃ­nh toÃ¡n Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a cÃ¡c sáº£n pháº©m. ThÆ°á»ng á»•n Ä‘á»‹nh hÆ¡n User-based khi lÆ°á»£ng ngÆ°á»i dÃ¹ng lá»›n hÆ¡n lÆ°á»£ng sáº£n pháº©m.

#### c. Matrix Factorization (ALS - Alternating Least Squares)
PhÃ¢n rÃ£ ma tráº­n Rating $R$ thÃ nh hai ma tráº­n tiá»m áº©n $P$ (User features) vÃ  $Q$ (Item features) sao cho $R \approx P \times Q^T$.
- **HÃ m máº¥t mÃ¡t (Loss Function):**
  $$L = \sum_{(u,i) \in \mathcal{K}} (r_{ui} - p_u q_i^T)^2 + \lambda (||p_u||^2 + ||q_i||^2)$$
- **Tá»‘i Æ°u hÃ³a:** Cá»‘ Ä‘á»‹nh $P$ Ä‘á»ƒ giáº£i $Q$ vÃ  ngÆ°á»£c láº¡i láº·p Ä‘i láº·p láº¡i cho Ä‘áº¿n khi há»™i tá»¥. Giáº£i phÆ°Æ¡ng trÃ¬nh Ä‘áº¡o hÃ m báº±ng khÃ´ng báº±ng NumPy Linear Algebra (`np.linalg.solve`).

### Ká»¹ thuáº­t NumPy Ä‘Ã£ sá»­ dá»¥ng
- **Vectorization:** Loáº¡i bá» hoÃ n toÃ n vÃ²ng láº·p Python khi tÃ­nh toÃ¡n Similarity vÃ  Prediction.
- **Broadcasting:** Sá»­ dá»¥ng Ä‘á»ƒ trá»« mean (center data) vÃ  nhÃ¢n trá»ng sá»‘ nhanh chÃ³ng.
- **Sparse Matrices (SciPy):** Sá»­ dá»¥ng `csr_matrix` Ä‘á»ƒ lÆ°u trá»¯ dá»¯ liá»‡u rating nháº±m tiáº¿t kiá»‡m RAM (do ma tráº­n ráº¥t thÆ°a).
- **Fancy Indexing:** Truy xuáº¥t dá»¯ liá»‡u train/test nhanh chÃ³ng.

---

## 4. CÃ i Ä‘áº·t & Thiáº¿t láº­p

YÃªu cáº§u mÃ´i trÆ°á»ng: Python 3.8+

1.  **Clone repository:**
    ```bash
    git clone https://github.com/chomnhim/AMAZON_Project.git
    cd AMAZON_Project
    ```

2.  **CÃ i Ä‘áº·t thÆ° viá»‡n:**
    ```bash
    pip install -r requirements.txt
    ```
    *(ThÆ° viá»‡n chÃ­nh: numpy, scipy, matplotlib, seaborn)*

3.  **Chuáº©n bá»‹ dá»¯ liá»‡u:**
    - Táº£i file `ratings_Beauty.csv` vÃ  Ä‘áº·t vÃ o thÆ° má»¥c `data/raw/`.

---

## 5. HÆ°á»›ng dáº«n sá»­ dá»¥ng

Cháº¡y cÃ¡c notebook theo thá»© tá»± sau Ä‘á»ƒ tÃ¡i hiá»‡n káº¿t quáº£:

1.  **`notebooks/01_data_exploration.ipynb`**: KhÃ¡m phÃ¡ dá»¯ liá»‡u, váº½ biá»ƒu Ä‘á»“ phÃ¢n phá»‘i Rating, User activity, Product popularity.
2.  **`notebooks/02_preprocessing.ipynb`**: LÃ m sáº¡ch dá»¯ liá»‡u, lá»c nhiá»…u, táº¡o ma tráº­n thÆ°a vÃ  chia táº­p dá»¯ liá»‡u.
3.  **`notebooks/03_modeling.ipynb`**: Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh (UserCF, ItemCF, ALS), Ä‘Ã¡nh giÃ¡ vÃ  so sÃ¡nh káº¿t quáº£.

---

## 6. Káº¿t quáº£ (Results)

ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p Validation/Test sá»­ dá»¥ng cÃ¡c Ä‘á»™ Ä‘o: RMSE, MAE vÃ  F1-Score@10.

### ğŸ“Š Báº£ng so sÃ¡nh hiá»‡u nÄƒng

| Metric | User-Based CF | Item-Based CF | ALS (Matrix Factorization) | Tá»‘t nháº¥t |
|:---|:---:|:---:|:---:|:---:|
| **RMSE** (Sai sá»‘ bÃ¬nh phÆ°Æ¡ng trung bÃ¬nh) | 0.9400 | 0.9661 | **0.9129** | **ALS** |
| **MAE** (Sai sá»‘ tuyá»‡t Ä‘á»‘i trung bÃ¬nh) | 0.6710 | 0.6624 | **0.6521** | **ALS** |
| **F1-Score@10** (Äá»™ Ä‘o xáº¿p háº¡ng) | 0.0111 | 0.0134 | **0.0151** | **ALS** |

![Model Comparison](data/processed/model_comparison.png)

### ğŸ’¡ PhÃ¢n tÃ­ch & Nháº­n xÃ©t

**1. Hiá»‡u nÄƒng tá»•ng thá»ƒ:**
- **MÃ´ hÃ¬nh ALS (Matrix Factorization) vÆ°á»£t trá»™i hoÃ n toÃ n:** ALS Ä‘áº¡t káº¿t quáº£ tá»‘t nháº¥t trÃªn cáº£ hai phÆ°Æ¡ng diá»‡n: dá»± Ä‘oÃ¡n Ä‘iá»ƒm sá»‘ chÃ­nh xÃ¡c nháº¥t (RMSE tháº¥p nháº¥t) vÃ  kháº£ nÄƒng gá»£i Ã½ Ä‘Ãºng sáº£n pháº©m cao nháº¥t (F1@10 cao nháº¥t).
- **Item-Based vs User-Based:** Item-Based cÃ³ RMSE cao hÆ¡n (dá»± Ä‘oÃ¡n Ä‘iá»ƒm sá»‘ lá»‡ch nhiá»u hÆ¡n) nhÆ°ng láº¡i cÃ³ F1-Score cao hÆ¡n User-Based. Äiá»u nÃ y cho tháº¥y Item-Based tuy dá»± Ä‘oÃ¡n Ä‘iá»ƒm sá»‘ cá»¥ thá»ƒ khÃ´ng chÃ­nh xÃ¡c báº±ng, nhÆ°ng láº¡i xáº¿p háº¡ng (ranking) cÃ¡c sáº£n pháº©m "Ä‘Ã¡ng mua" tá»‘t hÆ¡n User-Based.

**2. Táº¡i sao ALS hoáº¡t Ä‘á»™ng tá»‘t nháº¥t?**
- **Xá»­ lÃ½ Ma tráº­n thÆ°a (Sparsity):** Dá»¯ liá»‡u Amazon Beauty cÃ³ Ä‘á»™ thÆ°a lÃªn tá»›i **99.99%**. CÃ¡c thuáº­t toÃ¡n dá»±a trÃªn lÃ¡ng giá»ng (Memory-based nhÆ° User/Item CF) gáº·p khÃ³ khÄƒn lá»›n khi tÃ¬m kiáº¿m ngÆ°á»i dÃ¹ng/sáº£n pháº©m tÆ°Æ¡ng Ä‘á»“ng vÃ¬ cÃ³ quÃ¡ Ã­t Ä‘iá»ƒm dá»¯ liá»‡u chung. NgÆ°á»£c láº¡i, ALS (Model-based) hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch phÃ¢n rÃ£ ma tráº­n Ä‘á»ƒ há»c cÃ¡c **Ä‘áº·c trÆ°ng tiá»m áº©n (latent features)**, giÃºp "láº¥p Ä‘áº§y" cÃ¡c khoáº£ng trá»‘ng trong ma tráº­n hiá»‡u quáº£ hÆ¡n.
- **Kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a:** User-Based CF thÆ°á»ng bá»‹ nhiá»…u bá»Ÿi nhá»¯ng ngÆ°á»i dÃ¹ng cÃ³ hÃ nh vi Ä‘Ã¡nh giÃ¡ tháº¥t thÆ°á»ng. ALS giáº£m thiá»ƒu Ä‘iá»u nÃ y thÃ´ng qua tham sá»‘ Ä‘iá»u chuáº©n (regularization - $\lambda$), giÃºp mÃ´ hÃ¬nh Ã­t bá»‹ overfitting hÆ¡n.

**3. PhÃ¢n tÃ­ch cÃ¡c chá»‰ sá»‘:**
- **RMSE ~ 0.91:** NghÄ©a lÃ  trung bÃ¬nh mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n lá»‡ch khoáº£ng **0.9 sao** so vá»›i thá»±c táº¿. Vá»›i thang Ä‘iá»ƒm 1-5, Ä‘Ã¢y lÃ  má»©c cháº¥p nháº­n Ä‘Æ°á»£c Ä‘á»‘i vá»›i cÃ¡c há»‡ thá»‘ng gá»£i Ã½ sá»­ dá»¥ng dá»¯ liá»‡u thá»±c táº¿ nhiá»u nhiá»…u.
- **Precision/Recall tháº¥p (khoáº£ng 1-3%):** ÄÃ¢y lÃ  hiá»‡n tÆ°á»£ng bÃ¬nh thÆ°á»ng trong bÃ i toÃ¡n gá»£i Ã½ vá»›i khÃ´ng gian sáº£n pháº©m lá»›n (hÃ ng trÄƒm nghÃ¬n sáº£n pháº©m). Tuy nhiÃªn, má»©c F1@10 cá»§a ALS cao hÆ¡n **36%** so vá»›i User-Based (0.0151 vs 0.0111) lÃ  má»™t sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ.

**4. TÃ¡c Ä‘á»™ng cá»§a Ä‘áº·c Ä‘iá»ƒm dá»¯ liá»‡u:**
- **PhÃ¢n phá»‘i Long-tail:** Dá»¯ liá»‡u cho tháº¥y má»™t sá»‘ Ã­t sáº£n pháº©m phá»• biáº¿n chiáº¿m pháº§n lá»›n lÆ°á»£t Ä‘Ã¡nh giÃ¡.
    - **Item-Based CF** thÆ°á»ng cÃ³ xu hÆ°á»›ng gá»£i Ã½ cÃ¡c sáº£n pháº©m phá»• biáº¿n (Popularity bias), do Ä‘Ã³ nÃ³ Ä‘áº¡t Ä‘iá»ƒm Ranking (F1) tá»‘t hÆ¡n User-Based.
    - **User-Based CF** bá»‹ áº£nh hÆ°á»Ÿng náº·ng ná» bá»Ÿi cÃ¡c ngÆ°á»i dÃ¹ng Ã­t tÆ°Æ¡ng tÃ¡c (Cold-start users), dáº«n Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c tháº¥p nháº¥t.

**Káº¿t luáº­n:** Viá»‡c cÃ i Ä‘áº·t thuáº­t toÃ¡n **Matrix Factorization (ALS)** sá»­ dá»¥ng thuáº§n **NumPy** Ä‘Ã£ chá»©ng minh Ä‘Æ°á»£c hiá»‡u quáº£ vÆ°á»£t trá»™i so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng trÃªn bá»™ dá»¯ liá»‡u thÆ°a nhÆ° Amazon Beauty. ÄÃ¢y lÃ  lá»±a chá»n tá»‘i Æ°u Ä‘á»ƒ triá»ƒn khai há»‡ thá»‘ng gá»£i Ã½ trong thá»±c táº¿ cho bÃ i toÃ¡n nÃ y.

---

## 7. Cáº¥u trÃºc dá»± Ã¡n

```text
[cite_start]Cáº¥u trÃºc thÆ° má»¥c tuÃ¢n theo yÃªu cáº§u Ä‘á» bÃ i [cite: 56-72]:
project-name/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/		
â”‚   â”œâ”€â”€ raw/           	# Dá»¯ liá»‡u gá»‘c
â”‚   â””â”€â”€ processed/      # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â””â”€â”€ 03_modeling.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â””â”€â”€ models.py
```
---

## 8. ThÃ¡ch thá»©c & Giáº£i phÃ¡p

1.  **Váº¥n Ä‘á» bá»™ nhá»› (Memory Error):**
    - *ThÃ¡ch thá»©c:* Ma tráº­n tÆ°Æ¡ng Ä‘á»“ng (User-User) kÃ­ch thÆ°á»›c ~1M x 1M quÃ¡ lá»›n Ä‘á»ƒ lÆ°u trong RAM.
    - *Giáº£i phÃ¡p:* Sá»­ dá»¥ng `scipy.sparse` Ä‘á»ƒ lÆ°u trá»¯. TÃ­nh toÃ¡n theo tá»«ng batch (chunking) khi tÃ¬m K-lÃ¡ng giá»ng gáº§n nháº¥t thay vÃ¬ tÃ­nh toÃ n bá»™ ma tráº­n cÃ¹ng lÃºc.

2.  **Hiá»‡u nÄƒng tÃ­nh toÃ¡n:**
    - *ThÃ¡ch thá»©c:* VÃ²ng láº·p Python quÃ¡ cháº­m khi duyá»‡t qua hÃ ng triá»‡u ratings.
    - *Giáº£i phÃ¡p:* Vector hÃ³a toÃ n bá»™ cÃ¡c phÃ©p tÃ­nh cá»™ng, trá»«, nhÃ¢n ma tráº­n báº±ng NumPy Broadcasting vÃ  Dot product.

3.  **Dá»¯ liá»‡u thÆ°a (Sparsity):**
    - *ThÃ¡ch thá»©c:* 99.99% dá»¯ liá»‡u lÃ  rá»—ng, cÃ¡c thuáº­t toÃ¡n CF khÃ³ tÃ¬m Ä‘Æ°á»£c lÃ¡ng giá»ng.
    - *Giáº£i phÃ¡p:* Ãp dá»¥ng ká»¹ thuáº­t lá»c (iterative filtering) Ä‘á»ƒ giá»¯ láº¡i core-users vÃ  core-items, Ä‘áº£m báº£o máº­t Ä‘á»™ dá»¯ liá»‡u Ä‘á»§ Ä‘á»ƒ mÃ´ hÃ¬nh há»c.

---

## 9. HÆ°á»›ng phÃ¡t triá»ƒn

- **Tá»‘i Æ°u Hyperparameters:** Sá»­ dá»¥ng Grid Search Ä‘á»ƒ tÃ¬m tham sá»‘ tá»‘i Æ°u cho `k` (sá»‘ lÃ¡ng giá»ng/sá»‘ factors) vÃ  `lambda` (regularization).
- **Hybrid Model:** Káº¿t há»£p Content-based (dá»±a trÃªn mÃ´ táº£ sáº£n pháº©m) vá»›i Collaborative Filtering Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» Cold-start tá»‘t hÆ¡n.
- **Triá»ƒn khai:** XÃ¢y dá»±ng API Ä‘Æ¡n giáº£n vá»›i Flask/FastAPI Ä‘á»ƒ phá»¥c vá»¥ gá»£i Ã½ thá»i gian thá»±c.

---

## 10. TÃ¡c giáº£

**Há» vÃ  tÃªn:** [Nguyá»…n XUÃ¢n Quang]

**MSSV:** [23122047]

**Lá»›p:** 23TNT1

---
**LiÃªn há»‡:** Náº¿u cÃ³ tháº¯c máº¯c, vui lÃ²ng liÃªn há»‡ qua email [23122047@student.hcmus.edu.vn].

---

## 11. Giáº¥y phÃ©p (License)

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¢n phá»‘i dÆ°á»›i giáº¥y phÃ©p **MIT License**. Xem chi tiáº¿t táº¡i file [LICENSE](./LICENSE).